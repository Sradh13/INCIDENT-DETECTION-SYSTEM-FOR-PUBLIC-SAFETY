# -*- coding: utf-8 -*-
"""Incident Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wX-ODSUmR-MDaLylt_d3vcAUmQM4nTyg
"""

pip install tensorflow pandas matplotlib opencv-python twilio

from google.colab import drive
drive.mount('/content/drive')

img_path = "/content/drive/MyDrive/Threats/"
act_label = ['accident' , 'theft' , 'fire' , 'normal']
import pandas as pd
import os
import tensorflow as tf
import numpy as np

img_list = []
label_list = []
for label in act_label:
    for img_file in os.listdir(img_path+label):
        img_list.append(img_path+label+'/'+img_file)
        label_list.append(label)

df = pd.DataFrame({'img':img_list, 'label':label_list})


# Create a dataframe for mapping label
df_labels = {
    'accident' : 0,
    'theft' : 1,
    'fire' : 2,
    'normal' : 3,
    }

# Encode
df['encode_label'] = df['label'].map(df_labels)
df.head()
import cv2


X = []

for img in df['img']:
    ano = img
    img = cv2.imread(str(img))
    # img = augment_function(img)
    if (img is not None):
        img = cv2.resize(img, (96, 96))
        img = img/255
        X.append(img)
    else:
        print(ano)



y = df['encode_label']
from sklearn.model_selection import train_test_split
X_train, X_test_val, y_train, y_test_val = train_test_split(X, y)
X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val)

from keras.applications.vgg16 import VGG16

base_model = VGG16(input_shape=(96,96,3), include_top=False, weights='imagenet')

base_model.summary()
for layer in base_model.layers:
    layer.trainable = False
base_model.layers[-2].trainable = True
base_model.layers[-3].trainable = True
base_model.layers[-4].trainable = True
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
model = Sequential()
model.add(Input(shape=(96,96,3)))
model.add(base_model)
model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(len(act_label), activation='softmax'))
model.summary()
model.compile(
  optimizer="adam",
  loss='sparse_categorical_crossentropy',
  metrics=['acc'])


X_train = tf.convert_to_tensor(np.array(X_train))
X_val = tf.convert_to_tensor(np.array(X_val))
y_train = tf.convert_to_tensor(y_train.values)
y_val = tf.convert_to_tensor(y_val.values)



history = model.fit(tf.stack(X_train), tf.stack(y_train), epochs=5, validation_data=(X_val, y_val))
print(history)

# Get user input for the image file path
def predict_image(image_path, model, label_map):
    # Load and preprocess the image
    img = cv2.imread(image_path)

    if img is None:
        print("Could not load the image. Please check the file path.")
        return None, None
    img = cv2.resize(img, (96, 96))      # Resize to match training dimensions
    img = img / 255.0                     # Normalize pixel values
    img = np.expand_dims(img, axis=0)     # Add batch dimension

    # Predict the class
    predictions = model.predict(img)
    predicted_class_index = np.argmax(predictions)   # Get index of highest probability
    predicted_label = label_map[predicted_class_index]   # Map to class label
    confidence = np.max(predictions)   # Get confidence of the prediction

    return predicted_label, confidence


label_map = {0: 'accident', 1: 'theft', 2: 'fire', 3: 'normal'}
user_image_path = '/content/fir.png'


# Predict the class of the image
predicted_label, confidence = predict_image(user_image_path, model, label_map)
if predicted_label is not None:
    print(f"Predicted class: {predicted_label}, Confidence: {confidence:.2f}")



loss, accuracy = model.evaluate(X_val, y_val, verbose=0)
accuracy = accuracy*100
print("Accuracy:  {:.2f}".format(accuracy))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import numpy as np

# Get predictions for the validation set
y_pred_probs = model.predict(X_val)
y_pred = np.argmax(y_pred_probs, axis=1)

# Convert tensors to numpy arrays if necessary
if tf.is_tensor(y_val):
    y_val = y_val.numpy()

# Print accuracy
acc = accuracy_score(y_val, y_pred)
print("Accuracy: {:.2f}%".format(acc * 100))

# Print classification report (includes precision, recall, F1-score)
print("\nClassification Report:")
print(classification_report(y_val, y_pred, target_names=act_label))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

import matplotlib.pyplot as plt

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['acc'], label='Train Accuracy')
plt.plot(history.history['val_acc'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Over Epochs')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix

# Get predictions again (in case you haven't yet)
y_pred = np.argmax(model.predict(X_val), axis=1)
cm = confusion_matrix(y_val, y_pred)

# Plot using seaborn
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=act_label,
            yticklabels=act_label)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from twilio.rest import *

account_sid = 'AC9b7652022f1e1719ad3c22fb743528bc'
auth_token = 'de0dcc4560f7c3a4c2814f498a2b14e5'
client = Client(account_sid, auth_token)

if (predicted_label == 'fire'):
  msg = "fire"
  num = "+917339055880"
elif (predicted_label == 'accident'):
  msg = "accident"
  num = "+916369008404"
else:
  pass
message = client.messages.create(
    body=msg,
    from_='+17543251328', # Your Twilio number
    to= num  # Receiver's number
)


print("Message sent:", message.sid)